{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create empty hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Outputs\\remm_data_2019_base_year_20220526.h5\n"
     ]
    }
   ],
   "source": [
    "# store path for new hdf\n",
    "hdf_name = 'remm_data_2019_base_year_20220526'\n",
    "new_hdf = os.path.join('.\\\\Outputs', hdf_name + '.h5')\n",
    "print(new_hdf)\n",
    "\n",
    "# if the h5 exists already delete it; it will not overwrite\n",
    "if os.path.exists(new_hdf):\n",
    "    try:\n",
    "        new_hdf.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    os.remove(new_hdf)\n",
    "\n",
    "# Create empty h5   \n",
    "hdf = pd.HDFStore(new_hdf)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parcels\n",
    "parcels = pd.read_csv(r'E:\\REMM\\Base_Year_Data_2019\\v1\\edits\\parcels_20220513.csv')\n",
    "# hafb_tazids = pd.read_csv(r'.\\Inputs\\Hill_Air_Force_Base_TAZID832.csv')\n",
    "\n",
    "\n",
    "parcels['parcel_id'] = parcels['parcel_id_REMM']\n",
    "parcels['parent_parcel'] = parcels['parcel_id_REMM'] # crosswalked using old parcel id - parent parcel id relationship\n",
    "parcels['zone_id'] = parcels['TAZID_832']\n",
    "parcels.rename({'COUNTY_ID':'county_id'}, axis=1, inplace=True)\n",
    "\n",
    "# convert back to square feet for now, since the model is coded to used those units (parcel_acres is derived from shape_area)\n",
    "# parcels['shape_area'] = parcels['shape_area'] * 10.7639\n",
    "# parcels['shape_area'] = parcels['shape_area'].round(0).astype(int)\n",
    "\n",
    "parcels = parcels[['parcel_id_REMM', 'zone_id', 'CO_NAME', 'county_id', 'land_value',\n",
    "       'x', 'y', 'Split', 'parcel_acres',\n",
    "       'TAZID_832', 'TAZID_900', 'Old_PID', 'parent_parcel', 'elevation',\n",
    "       'fwy_exit', 'airport', 'rail_depot', 'stream', 'trail', 'university',\n",
    "       'shape_area', 'volume_one_way', 'volume_two_way', 'airport_distance',\n",
    "       'fwy_exit_dist', 'raildepot_dist', 'university_dist', 'trail_dist',\n",
    "       'stream_dist', 'train_station', 'rail_stn_dist', 'bus_rte_dist',\n",
    "       'bus_stop', 'bus_stop_dist', 'volume_two_way_nofwy', 'distsml_id',\n",
    "       'distmed_id', 'distlrg_id', 'zonal_ppa', 'parcel_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcel_id_REMM</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>CO_NAME</th>\n",
       "      <th>county_id</th>\n",
       "      <th>land_value</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Split</th>\n",
       "      <th>parcel_acres</th>\n",
       "      <th>TAZID_832</th>\n",
       "      <th>TAZID_900</th>\n",
       "      <th>Old_PID</th>\n",
       "      <th>parent_parcel</th>\n",
       "      <th>elevation</th>\n",
       "      <th>fwy_exit</th>\n",
       "      <th>airport</th>\n",
       "      <th>rail_depot</th>\n",
       "      <th>stream</th>\n",
       "      <th>trail</th>\n",
       "      <th>university</th>\n",
       "      <th>shape_area</th>\n",
       "      <th>volume_one_way</th>\n",
       "      <th>volume_two_way</th>\n",
       "      <th>airport_distance</th>\n",
       "      <th>fwy_exit_dist</th>\n",
       "      <th>raildepot_dist</th>\n",
       "      <th>university_dist</th>\n",
       "      <th>trail_dist</th>\n",
       "      <th>stream_dist</th>\n",
       "      <th>train_station</th>\n",
       "      <th>rail_stn_dist</th>\n",
       "      <th>bus_rte_dist</th>\n",
       "      <th>bus_stop</th>\n",
       "      <th>bus_stop_dist</th>\n",
       "      <th>volume_two_way_nofwy</th>\n",
       "      <th>distsml_id</th>\n",
       "      <th>distmed_id</th>\n",
       "      <th>distlrg_id</th>\n",
       "      <th>zonal_ppa</th>\n",
       "      <th>parcel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33496</th>\n",
       "      <td>35823</td>\n",
       "      <td>1001</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>35</td>\n",
       "      <td>22651200.0</td>\n",
       "      <td>1531671.508</td>\n",
       "      <td>7444871.339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.999832</td>\n",
       "      <td>1001</td>\n",
       "      <td>1134</td>\n",
       "      <td>43559.0</td>\n",
       "      <td>35823</td>\n",
       "      <td>1293.464774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>435592.6886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>4.80067</td>\n",
       "      <td>0.94616</td>\n",
       "      <td>3.16089</td>\n",
       "      <td>2.85429</td>\n",
       "      <td>1.02749</td>\n",
       "      <td>1.32079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124219</td>\n",
       "      <td>51.493291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104867</td>\n",
       "      <td>656.0</td>\n",
       "      <td>235</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>1284250.279</td>\n",
       "      <td>35823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       parcel_id_REMM  zone_id    CO_NAME  county_id  land_value            x  \\\n",
       "33496           35823     1001  Salt Lake         35  22651200.0  1531671.508   \n",
       "\n",
       "                 y  Split  parcel_acres  TAZID_832  TAZID_900  Old_PID  \\\n",
       "33496  7444871.339    0.0      9.999832       1001       1134  43559.0   \n",
       "\n",
       "       parent_parcel    elevation  fwy_exit  airport  rail_depot  stream  \\\n",
       "33496          35823  1293.464774       0.0      0.0         0.0     0.0   \n",
       "\n",
       "       trail  university   shape_area  volume_one_way  volume_two_way  \\\n",
       "33496    0.0         0.0  435592.6886             0.0           656.0   \n",
       "\n",
       "       airport_distance  fwy_exit_dist  raildepot_dist  university_dist  \\\n",
       "33496           4.80067        0.94616         3.16089          2.85429   \n",
       "\n",
       "       trail_dist  stream_dist  train_station  rail_stn_dist  bus_rte_dist  \\\n",
       "33496     1.02749      1.32079            0.0       0.124219     51.493291   \n",
       "\n",
       "       bus_stop  bus_stop_dist  volume_two_way_nofwy  distsml_id  distmed_id  \\\n",
       "33496       0.0       0.104867                 656.0         235          23   \n",
       "\n",
       "       distlrg_id    zonal_ppa  parcel_id  \n",
       "33496           8  1284250.279      35823  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels[parcels['parcel_id_REMM']==35823]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.put('parcels', parcels.set_index('parcel_id'), format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'building_sqft', 'building_type_id',\n",
       "       'non_residential_sqft', 'note', 'parcel_id', 'residential_units',\n",
       "       'stories', 'unit_price_non_residential', 'year_built',\n",
       "       'res_price_per_sqft', 'job_spaces'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings = pd.read_csv(r'E:\\REMM\\Base_Year_Data_2019\\v1\\edits\\buildings_20220513.csv')\n",
    "buildings_lu = {0:None,\n",
    "                1:1,\n",
    "                2:2,\n",
    "                3:3,\n",
    "                4:4,\n",
    "                5:5,\n",
    "                6:6,\n",
    "                7:7,\n",
    "                8:8,\n",
    "                9:6, \n",
    "                10:8,\n",
    "                11:8,\n",
    "                12:None,\n",
    "                13:5,\n",
    "                14:None,\n",
    "                15:None,\n",
    "                16:None,\n",
    "                99:None}\n",
    "\n",
    "# remap building types\n",
    "buildings['building_type_id'] = buildings['building_type_id'].map(buildings_lu)\n",
    "\n",
    "######################################\n",
    "# fill in some fake square footage and years (comment out later)\n",
    "######################################\n",
    "\n",
    "# fill in some fake numbers\n",
    "buildings.loc[(buildings['year_built'].isna() ==True) | (buildings['year_built'] == 0), 'year_built'] =  np.random.randint(1900, 2019, buildings[(buildings['year_built'].isna() ==True) | (buildings['year_built'] == 0)].shape[0])\n",
    "\n",
    "buildings.loc[((buildings['building_sqft'].isna() ==True) | (buildings['building_sqft'] == 0)) & (buildings['building_type_id'] == 3), \n",
    "              'building_sqft'] =  np.random.randint(10000, 200000, buildings[((buildings['building_sqft'].isna() ==True) | (buildings['building_sqft'] == 0)) & (buildings['building_type_id'] == 3)].shape[0])\n",
    "\n",
    "buildings.loc[((buildings['building_sqft'].isna() ==True) | (buildings['building_sqft'] == 0)) & (buildings['building_type_id'] != 3), \n",
    "              'building_sqft'] =  np.random.randint(1400, 14000, buildings[((buildings['building_sqft'].isna() ==True) | (buildings['building_sqft'] == 0)) & (buildings['building_type_id'] != 3)].shape[0])\n",
    "\n",
    "buildings.loc[((buildings['non_residential_sqft'].isna() ==True) | (buildings['non_residential_sqft'] == 0)) & (buildings['building_type_id'].isin([1,2]) == False), \n",
    "              'non_residential_sqft'] = buildings['building_sqft']\n",
    "\n",
    "buildings.loc[((buildings['non_residential_sqft'].isna() ==True) | (buildings['non_residential_sqft'] == 0)) & (buildings['building_type_id'].isin([1,2]) == True), \n",
    "              'non_residential_sqft'] = 0\n",
    "\n",
    "buildings.loc[(buildings['residential_units'].isna() ==True), \n",
    "              'residential_units'] =  0\n",
    "\n",
    "buildings.loc[(buildings['unit_price_non_residential'].isna() ==True), \n",
    "              'unit_price_non_residential'] =  0\n",
    "\n",
    "mean = buildings['res_price_per_sqft'].mean()\n",
    "buildings.loc[((buildings['res_price_per_sqft'].isna() ==True) | (buildings['res_price_per_sqft'] == 0)) & (buildings['building_type_id'].isin([1,2]) == True), \n",
    "              'res_price_per_sqft'] = mean\n",
    "\n",
    "buildings.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "buildings.loc[((buildings['res_price_per_sqft'].isna() ==True) | (buildings['res_price_per_sqft'] == 0)) & (buildings['building_type_id'].isin([1,2]) == False), \n",
    "              'res_price_per_sqft'] = 0\n",
    "####################################################\n",
    "\n",
    "# subset to buildings with a building type\n",
    "buildings = buildings[buildings['building_type_id'] >= 1]\n",
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.put('buildings', buildings.set_index('building_id'), format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jobs_id', 'building_id', 'cid', 'sector_id'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv(r'E:\\REMM\\Base_Year_Data_2019\\v1\\edits\\jobs_20220513.csv')\n",
    "jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.put('jobs', jobs.set_index('jobs_id'), format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['household_id', 'cars', 'household_type_id', 'persons', 'income',\n",
       "       'workers', 'children', 'age_of_head', 'race_id', 'familyhh', 'block_id',\n",
       "       'cid', 'building_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "households = pd.read_csv(r'E:\\REMM\\Base_Year_Data_2019\\v1\\edits\\households_20220513.csv')\n",
    "households.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.put('households', households, format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add travel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['from_zone_id', 'to_zone_id', 'travel_time', 'travel_time_transit',\n",
       "       'log0', 'log1', 'log2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_data = pd.read_csv(r'E:\\REMM\\Base_Year_Data_2019\\v1\\travel_data_2015.csv')\n",
    "travel_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.put('travel_data', travel_data.set_index(['from_zone_id', 'to_zone_id']), format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add zoning baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parcel_id', 'max_dua', 'max_far', 'max_height', 'type1', 'type2',\n",
       "       'type3', 'type4', 'type5', 'type6', 'type7', 'type8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zoning_baseline = pd.read_csv(r'E:\\REMM\\Base_Year_Data_2019\\v1\\zoning_baseline2019.csv')\n",
    "zoning_baseline = pd.read_csv(r'E:\\REMM\\Base_Year_Data_2019\\v1\\edits\\zoning_baseline_20220513.csv')\n",
    "zoning_baseline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.put('zoning_baseline', zoning_baseline.set_index('parcel_id'), format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the h5\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip it up for distribution\n",
    "ZipFile(os.path.join('.\\\\Outputs',hdf_name + '.zip'), mode='w').write(new_hdf, arcname=hdf_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in hdf5 \n",
    "# store1 = pd.HDFStore('.\\\\Data\\\\remm_data_2015_base_year_02082019.h5')\n",
    "# tables = list(store1.keys())\n",
    "# tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store1['buildings'].head(5)\n",
    "# store1['buildings_for_estimation']\n",
    "# store1['buildings_for_estimation_grouped'].head(5)\n",
    "# store1['employment_controls'].head(5)\n",
    "# store1['household_controls'].head(5)\n",
    "# store1['household_for_estimation'].head(5)\n",
    "# store1['households'].head(5)\n",
    "# store1['households_for_estimation'].head(5)\n",
    "# store1['households_for_estimation1'].head(5)\n",
    "# store1['jobs'].head(5)\n",
    "# store1['parcels'].head(5)\n",
    "# store1['travel_data'].head(5)\n",
    "# store1['valid_parcels'].head(5)\n",
    "# store1['zoning'].head(5)\n",
    "# store1['zoning_base_line'].head(5)\n",
    "# store1['zoning_baseline'].head(5)\n",
    "# store1['zoning_for_parcels'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in hdf5 \n",
    "# store2 = pd.HDFStore('.\\\\Results\\\\remm_data_2015_base_year_09102020.h5')\n",
    "# tables = list(store2.keys())\n",
    "# tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store2['buildings'].head(5)\n",
    "# store2['buildings_for_estimation']\n",
    "# store2['buildings_for_estimation_grouped'].head(5)\n",
    "# store2['employment_controls'].head(5)\n",
    "# store2['household_controls'].head(5)\n",
    "# store2['household_for_estimation'].head(5)\n",
    "# store2['households'].head(5)\n",
    "# store2['households_for_estimation'].head(5)\n",
    "# store2['households_for_estimation1'].head(5)\n",
    "# store2['jobs'].head(5)\n",
    "# store2['parcels'].head(5)\n",
    "# store2['travel_data'].head(5)\n",
    "# store2['valid_parcels'].head(5)\n",
    "# store2['zoning'].head(5)\n",
    "# store2['zoning_base_line'].head(5)\n",
    "# store2['zoning_baseline'].head(5)\n",
    "# store2['zoning_for_parcels'].head(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcba146b744ef62af8ef1a169a65f5cba67ffcb67445c2d993d6e4d88fe0ea63"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
