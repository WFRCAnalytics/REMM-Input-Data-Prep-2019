{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheckedOut'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Outputs'):\n",
    "    os.makedirs('Outputs')\n",
    "    \n",
    "outputs = ['.\\\\Outputs', \"mmn_scratch.gdb\", 'mmn_results.gdb']\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "gdb2 = os.path.join(outputs[0], outputs[2])\n",
    "\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[1])\n",
    "\n",
    "if not arcpy.Exists(gdb2):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create empty hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Outputs\\Multi_Modal_Network_20220428.h5\n"
     ]
    }
   ],
   "source": [
    "# store path for new hdf\n",
    "hdf_name = 'Multi_Modal_Network_20220428'\n",
    "new_hdf = os.path.join('.\\\\Outputs', hdf_name + '.h5')\n",
    "print(new_hdf)\n",
    "\n",
    "# if the h5 exists already delete it; it will not overwrite\n",
    "if os.path.exists(new_hdf):\n",
    "    try:\n",
    "        new_hdf.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    os.remove(new_hdf)\n",
    "\n",
    "# Create empty h5   \n",
    "hdf = pd.HDFStore(new_hdf)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect original network tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/edges', '/nodes']\n"
     ]
    }
   ],
   "source": [
    "osm = r\".\\Inputs\\osm_wfrc.h5\"\n",
    "store = pd.HDFStore(osm)\n",
    "tables = list(store.keys())\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31354714</th>\n",
       "      <td>25323002</td>\n",
       "      <td>25323003</td>\n",
       "      <td>58.672306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51904539</th>\n",
       "      <td>40243023</td>\n",
       "      <td>40243025</td>\n",
       "      <td>292.575745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51904540</th>\n",
       "      <td>40243025</td>\n",
       "      <td>40243028</td>\n",
       "      <td>331.527008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51904541</th>\n",
       "      <td>40243028</td>\n",
       "      <td>6240765</td>\n",
       "      <td>127.711517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51904542</th>\n",
       "      <td>40243024</td>\n",
       "      <td>40243025</td>\n",
       "      <td>123.560577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              from        to      weight\n",
       "31354714  25323002  25323003   58.672306\n",
       "51904539  40243023  40243025  292.575745\n",
       "51904540  40243025  40243028  331.527008\n",
       "51904541  40243028   6240765  127.711517\n",
       "51904542  40243024  40243025  123.560577"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['edges'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35651665</th>\n",
       "      <td>1540812.750</td>\n",
       "      <td>7442087.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35651666</th>\n",
       "      <td>1540787.500</td>\n",
       "      <td>7440621.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35651667</th>\n",
       "      <td>1540787.125</td>\n",
       "      <td>7440260.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35651668</th>\n",
       "      <td>1540772.250</td>\n",
       "      <td>7439106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35651669</th>\n",
       "      <td>1531160.500</td>\n",
       "      <td>7419242.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    x          y\n",
       "35651665  1540812.750  7442087.5\n",
       "35651666  1540787.500  7440621.5\n",
       "35651667  1540787.125  7440260.5\n",
       "35651668  1540772.250  7439106.0\n",
       "35651669  1531160.500  7419242.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nodes\n",
    "store['nodes'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Multimodal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz900 = r\".\\Inputs\\TAZ_900_ID_Only.shp\"\n",
    "reporting_areas = r\".\\Inputs\\REMM_Reporting_Areas.shp\"\n",
    "mmn = r\".\\Inputs\\MM_NetworkDataset_04072022.gdb\"\n",
    "network = os.path.join(mmn, 'NetworkDataset\\\\BikePedAuto')\n",
    "network_lyr = arcpy.MakeFeatureLayer_management(network,\"network_lyr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset network using TAZ boundary and Cartocode Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, May 4, 2022 3:28:29 PM\",\"Succeeded at Wednesday, May 4, 2022 3:28:35 PM (Elapsed Time: 6.87 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\mmn_scratch.gdb\\\\filtered_lines'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter using modeling area\n",
    "arcpy.SelectLayerByLocation_management(network_lyr, 'INTERSECT', reporting_areas, selection_type='NEW_SELECTION')\n",
    "\n",
    "# filter based on cartocode\n",
    "query = \"\"\" CartoCode NOT IN ('1 Interstates','10 Other Federal Aid Eligible Local Roads','7 Ramps, Collectors','13 Non-road feature','14 Driveway','15 Proposed') \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(network_lyr, 'SUBSET_SELECTION', query)\n",
    "\n",
    "# copy the line features\n",
    "filtered_lines = arcpy.FeatureClassToFeatureClass_conversion(network_lyr, gdb, 'filtered_lines')\n",
    "\n",
    "# Add unique ID\n",
    "unique_id_field = 'id'\n",
    "arcpy.AddField_management(filtered_lines, field_name=unique_id_field, field_type='LONG')\n",
    "arcpy.CalculateField_management(filtered_lines, unique_id_field, '\"!OBJECTID!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--generating start points\n",
      "--checking for extra start points\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, May 4, 2022 3:29:03 PM\",\"Succeeded at Wednesday, May 4, 2022 3:29:10 PM (Elapsed Time: 7.18 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\mmn_scratch.gdb\\\\start_pts'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--generating start points')\n",
    "start_pts = arcpy.FeatureVerticesToPoints_management(filtered_lines, os.path.join(gdb, 'start_pts_initial'), 'START')\n",
    "\n",
    "# Delete extra Start nodes, accounts for rare instance of multiple end nodes created\n",
    "print('--checking for extra start points')\n",
    "arcpy.AddField_management(start_pts, field_name='Temp_ID', field_type='LONG')\n",
    "arcpy.CalculateField_management(start_pts, 'Temp_ID', '\"!OBJECTID!\"')\n",
    "start_pts_sorted = arcpy.Sort_management(start_pts, os.path.join(gdb, 'start_pts'), sort_field=[[\"Temp_ID\", \"ASCENDING\"]])\n",
    "\n",
    "previous_id = None\n",
    "with arcpy.da.UpdateCursor(start_pts_sorted, ['temp_id']) as cursor:\n",
    "    for row in cursor:\n",
    "        \n",
    "        if row[0] == previous_id:\n",
    "            #print(\"--Current:{}, Previous:{}\".format(row[0], previous_id))\n",
    "            cursor.deleteRow()\n",
    "        previous_id = row[0]\n",
    "\n",
    "arcpy.DeleteField_management(start_pts, 'Temp_ID')\n",
    "start_pts = start_pts_sorted\n",
    "\n",
    "# add xy coords to start points\n",
    "arcpy.AddField_management(start_pts, field_name=\"xcoord\", field_type='double')\n",
    "arcpy.AddField_management(start_pts, field_name=\"ycoord\", field_type='double')\n",
    "\n",
    "# this might allow this section to run in command line\n",
    "with arcpy.da.UpdateCursor(start_pts, ['xcoord', 'ycoord', 'SHAPE@X', 'SHAPE@Y']) as cursor:\n",
    "    for row in cursor:\n",
    "        row[0] = row[2]\n",
    "        row[1] = row[3]\n",
    "        cursor.updateRow(row)\n",
    "        \n",
    "# create xy key to start points\n",
    "arcpy.AddField_management(start_pts, field_name=\"XY_Key\", field_type='string')\n",
    "arcpy.CalculateField_management(start_pts,\"XY_Key\",'\"!{}!|!{}!\"'.format('xcoord', 'ycoord'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--generating end points\n",
      "--checking for extra end points\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, May 4, 2022 3:29:38 PM\",\"Succeeded at Wednesday, May 4, 2022 3:29:45 PM (Elapsed Time: 7.21 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\mmn_scratch.gdb\\\\end_pts'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--generating end points')\n",
    "\n",
    "# get end points for each line\n",
    "end_pts = arcpy.FeatureVerticesToPoints_management(filtered_lines, os.path.join(gdb, 'end_pts_initial'), 'END')\n",
    "\n",
    "# Delete extra End nodes, accounts for rare instance of multiple end nodes created\n",
    "print('--checking for extra end points')\n",
    "arcpy.AddField_management(end_pts, field_name='Temp_ID', field_type='LONG')\n",
    "arcpy.CalculateField_management(end_pts, 'Temp_ID', '\"!OBJECTID!\"')\n",
    "end_pts_sorted = arcpy.Sort_management(end_pts, os.path.join(gdb, 'end_pts'), sort_field=[[\"Temp_ID\", \"DESCENDING\"]])\n",
    "\n",
    "previous_id = None\n",
    "with arcpy.da.UpdateCursor(end_pts_sorted, ['temp_id']) as cursor:\n",
    "    for row in cursor:\n",
    "        \n",
    "        if row[0] == previous_id:\n",
    "            #print(\"--Current:{}, Previous:{}\".format(row[0], previous_id))\n",
    "            cursor.deleteRow()\n",
    "        previous_id = row[0]\n",
    "\n",
    "arcpy.DeleteField_management(end_pts, 'Temp_ID')\n",
    "end_pts = end_pts_sorted\n",
    "\n",
    "# add xy coords to end points\n",
    "arcpy.AddField_management(end_pts, field_name=\"xcoord\", field_type='double')\n",
    "arcpy.AddField_management(end_pts, field_name=\"ycoord\", field_type='double')\n",
    "\n",
    "# this might allow this section to run in command line\n",
    "with arcpy.da.UpdateCursor(end_pts, ['xcoord', 'ycoord', 'SHAPE@X', 'SHAPE@Y']) as cursor:\n",
    "    for row in cursor:\n",
    "        row[0] = row[2]\n",
    "        row[1] = row[3]\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# add xy key to end points\n",
    "arcpy.AddField_management(end_pts, field_name=\"XY_Key\", field_type='string')\n",
    "arcpy.CalculateField_management(end_pts,\"XY_Key\",'\"!{}!|!{}!\"'.format('xcoord', 'ycoord'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join keys from lines and merge start and end points together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--merging start and end points\n",
      "--deleting duplicate nodes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, May 4, 2022 3:30:16 PM\",\"148320 duplicate(s) from 74619 group(s) deleted.\",\"Succeeded at Wednesday, May 4, 2022 3:30:29 PM (Elapsed Time: 13.40 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\mmn_scratch.gdb\\\\merged_pts'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_lines_lyr = arcpy.MakeFeatureLayer_management(filtered_lines,\"filtered_lines\")\n",
    "\n",
    "# join with centerlines, copy xy key\n",
    "arcpy.AddJoin_management(filtered_lines_lyr, unique_id_field, start_pts, unique_id_field)\n",
    "arcpy.CalculateField_management(filtered_lines_lyr,\"Start_Key\",'!{}!'.format('start_pts.XY_Key'))\n",
    "arcpy.RemoveJoin_management (filtered_lines_lyr)\n",
    "\n",
    "# join with centerlines, copy xy key\n",
    "arcpy.AddJoin_management(filtered_lines_lyr, unique_id_field, end_pts, unique_id_field)\n",
    "arcpy.CalculateField_management(filtered_lines_lyr,\"End_Key\",'!{}!'.format('end_pts.XY_Key'))\n",
    "arcpy.RemoveJoin_management (filtered_lines_lyr)\n",
    "\n",
    "# Create 'both ends' nodes data set by merging start nodes and end nodes\n",
    "print('--merging start and end points')    \n",
    "merged_pts = arcpy.Merge_management([start_pts, end_pts], os.path.join(gdb, \"merged_pts\"))\n",
    "\n",
    "# Remove duplicate nodes\n",
    "print('--deleting duplicate nodes')\n",
    "arcpy.DeleteIdentical_management(merged_pts, \"XY_Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Links\n"
     ]
    }
   ],
   "source": [
    "print('Creating Links') \n",
    "\n",
    "# calculate distance in meters\n",
    "arcpy.AddField_management(filtered_lines, field_name=\"weight\", field_type='float')\n",
    "with arcpy.da.UpdateCursor(filtered_lines, ['weight', 'SHAPE@LENGTH']) as cursor:\n",
    "    for row in cursor:\n",
    "        row[0] = row[1]\n",
    "        cursor.updateRow(row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table formatting and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final outputs\n",
      "--formatting nodes\n",
      "--exporting nodes to shape, csv, and h5\n"
     ]
    }
   ],
   "source": [
    "print('Creating final outputs')\n",
    "nodes_dataframe  = pd.DataFrame.spatial.from_featureclass(merged_pts[0])\n",
    "links_dataframe  = pd.DataFrame.spatial.from_featureclass(filtered_lines[0])\n",
    "\n",
    "print('--formatting nodes')\n",
    "nodes_dataframe_formatted = nodes_dataframe[['OBJECTID', 'xcoord', 'ycoord', 'XY_Key','SHAPE']].copy()\n",
    "# nodes_dataframe_formatted = nodes_dataframe_formatted.rename(columns={\"OBJECTID\": \"node_id\"})\n",
    "# nodes_dataframe_formatted = nodes_dataframe_formatted.sort_values(by=['node_id'])\n",
    "nodes_dataframe_formatted.columns = ['node_id', 'x', 'y','XY_Key','SHAPE']\n",
    "nodes_dataframe_formatted = nodes_dataframe_formatted.sort_values(by=['node_id'])\n",
    "\n",
    "print('--exporting nodes to shape, csv, and h5')\n",
    "nodes_dataframe_formatted.spatial.to_featureclass(location=os.path.join(gdb2, 'nodes'),sanitize_columns=False)\n",
    "\n",
    "del nodes_dataframe_formatted['SHAPE']\n",
    "nodes_dataframe_formatted[['node_id', 'x', 'y']].to_csv(r'.\\Outputs\\nodes.csv',index=False)\n",
    "hdf.put('nodes', nodes_dataframe_formatted[['node_id', 'x', 'y']].set_index('node_id'), format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'Name', 'Oneway', 'Speed', 'AutoNetwork', 'BikeNetwork',\n",
       "       'PedNetwork', 'SourceData', 'DriveTime', 'BikeTime', 'PedestrianTime',\n",
       "       'Length_Miles', 'ConnectorNetwork', 'CartoCode', 'AADT', 'AADT_YR',\n",
       "       'BIKE_L', 'BIKE_R', 'VERT_LEVEL', 'id', 'Start_Key', 'End_Key',\n",
       "       'weight', 'SHAPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--formatting links\n",
      "--exporting links to shape, csv, and h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jreynolds\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-remm\\lib\\site-packages\\tables\\path.py:155: NaturalNameWarning: object name is a Python keyword: 'from'; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    }
   ],
   "source": [
    "print('--formatting links')\n",
    "\n",
    "# Create from/to node columns\n",
    "links_dataframe = links_dataframe.assign(from_node='', to_node='', from_x='', from_y='', to_x='', to_y='')\n",
    "\n",
    "# Join with nodes to get start node IDs\n",
    "links_dataframe_temp = links_dataframe.merge(nodes_dataframe_formatted, left_on = 'Start_Key', right_on ='XY_Key' , how='inner')\n",
    "links_dataframe_temp['from_node'] = links_dataframe_temp['node_id']\n",
    "links_dataframe_temp['from_x'] = links_dataframe_temp['x']\n",
    "links_dataframe_temp['from_y'] = links_dataframe_temp['y']\n",
    "\n",
    "# Join with nodes to get end node IDs\n",
    "links_dataframe_temp = links_dataframe_temp.merge(nodes_dataframe_formatted, left_on = 'End_Key', right_on='XY_Key' , how='inner')\n",
    "links_dataframe_temp['to_node'] = links_dataframe_temp['node_id_y']\n",
    "links_dataframe_temp['to_x'] = links_dataframe_temp['x_y']\n",
    "links_dataframe_temp['to_y'] = links_dataframe_temp['y_y']\n",
    "\n",
    "# subset and rename columns\n",
    "links_dataframe_formatted = links_dataframe_temp[['OBJECTID', 'from_node', 'to_node', 'weight','from_x', 'from_y', 'to_x', 'to_y', 'SHAPE']].copy()\n",
    "links_dataframe_formatted = links_dataframe_formatted.rename(columns={\"OBJECTID\": \"link_id\"})\n",
    "links_dataframe_formatted = links_dataframe_formatted.sort_values(by=['link_id'])\n",
    "links_field_names = ['edge_id',  'from','to', 'weight','from_x', 'from_y', 'to_x', 'to_y','SHAPE']\n",
    "links_dataframe_formatted.columns = links_field_names\n",
    "links_dataframe_formatted['weight'] = links_dataframe_formatted['weight'].round(2)\n",
    "\n",
    "print('--exporting links to shape, csv, and h5')\n",
    "links_dataframe_formatted.spatial.to_featureclass(location=os.path.join(gdb2, 'edges'),sanitize_columns=False)\n",
    "\n",
    "# export to csv and h5\n",
    "del links_dataframe_formatted['SHAPE']\n",
    "del links_dataframe_formatted['from_x']\n",
    "del links_dataframe_formatted['from_y']\n",
    "del links_dataframe_formatted['to_x']\n",
    "del links_dataframe_formatted['to_y']\n",
    "links_dataframe_formatted.to_csv(r'.\\Outputs\\edges.csv',index=False)\n",
    "hdf.put('edges', links_dataframe_formatted.set_index('edge_id'), format='t', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the h5\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip it up for distribution\n",
    "ZipFile(os.path.join('.\\\\Outputs', hdf_name + '.zip'), mode='w').write(new_hdf, arcname=hdf_name + '.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d317b2672061d56524fcc1a94907fb406961cfb6f073b94c4a68211629b9774"
  },
  "kernelspec": {
   "display_name": "Clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
