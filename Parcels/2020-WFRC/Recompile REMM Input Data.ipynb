{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = r\".\\Inputs\\WFRC_Non_Residential_Parcels.gdb\\Non_Residential_Parcels\"\n",
    "hui = r\"E:\\Projects\\Housing-Unit-Inventory\\Current_Version\\wfrc_mag_housing_inventory_2020_20220209.gdb\\housing_inventory_2020_20220209\"\n",
    "mag_parcels = r'.\\Inputs\\MAG_REMM_Parcels_for_Splitting.gdb\\MAG_REMM_Parcels_for_splitting'\n",
    "raw_parcel_pts = r'.\\Inputs\\parcel_centroids.gdb\\wfrc_centroids'\n",
    "addr_pts = r'.\\Inputs\\addr_pts.gdb\\addr_pts_wfrc_mag'\n",
    "old_taz = r'.\\Inputs\\TAZ_832_ID_Only.shp'\n",
    "new_taz = r'.\\Inputs\\TAZ_900_ID_Only.shp'\n",
    "census_tracts = r'.\\Inputs\\tl_2018_49_tract.shp'\n",
    "centers = r'.\\Inputs\\WFRC_Centers_MaxFAR.shp'\n",
    "nonres_pts = r'.\\Inputs\\remm_base_year_2015.gdb\\nonres_sqft_2015_pts'\n",
    "base_year_surface1 = r\".\\Inputs\\zoning_surface.gdb\\base_year_surface_far\"\n",
    "base_year_surface2 = r\".\\Inputs\\zoning_surface.gdb\\base_year_surface_maxdua_year_built\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Outputs'):\n",
    "    os.makedirs('Outputs')\n",
    "    \n",
    "outputs = ['.\\\\Outputs', \"temp_file.gdb\", 'remm_base_year_2019.gdb']\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "gdb2 = os.path.join(outputs[0], outputs[2])\n",
    "\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[1])\n",
    "\n",
    "if not arcpy.Exists(gdb2):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Input-Data-Prep-2019\\\\Parcels\\\\2020-WFRC\\\\Outputs\\\\temp_file.gdb\\\\_00_hui_copy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~5 min\n",
    "hui_sdf = pd.DataFrame.spatial.from_featureclass(hui)\n",
    "hui_sdf = hui_sdf[['TYPE', 'IS_OUG', 'COUNTY', 'UNIT_COUNT', 'DUA','ACRES', 'TOT_BD_FT2', 'TOT_VALUE', 'APX_BLT_YR', 'UNIT_ID', 'SHAPE']].copy() # add floor count back later, can use centroids from parcels\n",
    "hui_sdf.columns = ['TYPE', 'IS_OUG', 'COUNTY_NAME', 'UNIT_COUNT', 'DUA','PARCEL_ACRES', 'BLDG_SQFT', 'TOTAL_MKT_VALUE', 'BUILT_YR','UNIT_ID', 'SHAPE']\n",
    "hui_sdf['UNIT_ID'] = hui_sdf.index + 1\n",
    "hui_copy =  os.path.join(gdb, '_00_hui_copy')\n",
    "hui_sdf.spatial.to_featureclass(location=hui_copy,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy hui\n",
    "# hui_copy = arcpy.FeatureClassToFeatureClass_conversion(hui, gdb, '_00_hui_copy')\n",
    "arcpy.CalculateField_management(hui_copy, \"TOTAL_MKT_VALUE\", \"\"\"0\"\"\", \"PYTHON3\")\n",
    "\n",
    "# use spatial join to summarize TOTAL_MKT_VALUE, LAND_MKT_VALUE, BLDG_SQFT\n",
    "target_features = hui_copy\n",
    "join_features = raw_parcel_pts\n",
    "output_features = os.path.join(gdb, \"_00_hui_pc_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('TOTAL_MKT_VALUE')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Sum'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('LAND_MKT_VALUE')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Sum'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('BLDG_SQFT')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Sum'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post process hui\n",
    "sj_sdf = pd.DataFrame.spatial.from_featureclass(sj[0])\n",
    "sj_sdf = sj_sdf[['UNIT_ID', 'TOTAL_MKT_VALUE','LAND_MKT_VALUE','BLDG_SQFT', 'COUNTY_NAME']].copy()\n",
    "sj_sdf.columns = ['UNIT_ID', 'TOTAL_MKT_VALUE_NEW','LAND_MKT_VALUE','BLDG_SQFT_NEW', 'COUNTY_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = hui_sdf.merge(sj_sdf, left_on=['UNIT_ID','COUNTY_NAME'],right_on=['UNIT_ID','COUNTY_NAME'],how='left')\n",
    "merged['PARCEL_ACRES'] = pd.to_numeric(merged['PARCEL_ACRES'].round(4)) \n",
    "\n",
    "# recalc the building type\n",
    "merged.loc[(merged['TYPE'] == 'single_family'), 'building_type_id'] = 1\n",
    "merged.loc[(merged['TYPE'] == 'multi_family'), 'building_type_id'] = 2\n",
    "\n",
    "# if current value is zero, update\n",
    "merged.loc[((merged['TOTAL_MKT_VALUE'] == 0) | (merged['TOTAL_MKT_VALUE'].isnull() == True)) & \n",
    "            ((merged['TOTAL_MKT_VALUE_NEW'] > 0) & (merged['TOTAL_MKT_VALUE_NEW'] < merged['TOTAL_MKT_VALUE'])), 'TOTAL_MKT_VALUE'] = merged['TOTAL_MKT_VALUE_NEW']\n",
    "\n",
    "# merged['TOTAL_MKT_VALUE'] =  merged['TOTAL_MKT_VALUE_NEW']\n",
    "\n",
    "merged.loc[((merged['BLDG_SQFT'] == 0) | (merged['BLDG_SQFT'].isnull() == True)) & \n",
    "            (merged['BLDG_SQFT_NEW'] != 0), 'BLDG_SQFT'] = merged['BLDG_SQFT_NEW']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391838, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Input-Data-Prep-2019\\\\Parcels\\\\2020-WFRC\\\\Outputs\\\\temp_file.gdb\\\\_01_hui_post_process'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hui_post_process = os.path.join(gdb, \"_01_hui_post_process\")\n",
    "merged.spatial.to_featureclass(location=hui_post_process,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all parcels within buffered housing unit inventory parcels and delete\n",
    "hui_buff = arcpy.Buffer_analysis(hui_post_process, os.path.join(gdb, \"_02_hui_buffer_1_25m\"), '1.25 METERS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 28, 2022 10:50:57 AM\",\"Succeeded at Thursday, April 28, 2022 10:50:58 AM (Elapsed Time: 0.17 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '_03_parcels_copy_Layer2'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select and remove parcels already existing in the housing inventory\n",
    "parcels_copy = arcpy.FeatureClassToFeatureClass_conversion(parcels, gdb, '_03_parcels_copy')\n",
    "parcels_with_selection = arcpy.SelectLayerByLocation_management(parcels_copy, 'WITHIN', hui_buff)\n",
    "arcpy.FeatureClassToFeatureClass_conversion(parcels_with_selection, gdb, '_02_parcels_removed')\n",
    "arcpy.DeleteFeatures_management(parcels_with_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add reforamtted hui parcels to main parcel dataset\n",
    "parcels_reunited = arcpy.Merge_management([parcels_with_selection, hui_post_process], os.path.join(gdb, '_04_WFRC_Reunited_Parcels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate WFRC Road Polygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_reunited_lyr = arcpy.MakeFeatureLayer_management(parcels_reunited, 'parcels_split_merge_lyr') \n",
    "arcpy.AddField_management(parcels_reunited_lyr, 'Thinness', 'FLOAT')\n",
    "arcpy.CalculateField_management(parcels_reunited_lyr, field='Thinness', expression=\"(4 * math.pi* !Shape_Area!) / (!Shape_Length! * !Shape_Length!)\", expression_type=\"PYTHON3\")\n",
    "query = \"\"\"(Thinness < 0.26 And building_type_id NOT IN (1, 2,3, 5, 4, 10, 3, 7, 8,9,10,11,12,13, 14, 15)) And PARCEL_ACRES > 0.025 And \n",
    "            PARCEL_ID NOT IN ('22081850140000', '15011090062000','110810001') And agriculture <> 1\"\"\"\n",
    "\n",
    "arcpy.SelectLayerByAttribute_management(parcels_reunited_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# exclude parcels that overlap with pts from selection\n",
    "do_not_delete = '.\\inputs\\do_not_delete_thinness.shp'\n",
    "arcpy.SelectLayerByLocation_management(in_layer=parcels_reunited_lyr, overlap_type=\"INTERSECT\",\n",
    "                                       select_features=do_not_delete,\n",
    "                                       selection_type='REMOVE_FROM_SELECTION')\n",
    "\n",
    "parcels_reunited_lyr = arcpy.DeleteFeatures_management(parcels_reunited_lyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with MAG Parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Input-Data-Prep-2019\\\\Parcels\\\\2020-WFRC\\\\Outputs\\\\temp_file.gdb\\\\_04_mag_parcels_processed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize\n",
    "mag_parcels_sdf = pd.DataFrame.spatial.from_featureclass(mag_parcels)\n",
    "mag_parcels_sdf.loc[(mag_parcels_sdf['OUG_ID']>0), 'IS_OUG'] = '1'\n",
    "mag_parcels_sdf.loc[(mag_parcels_sdf['OUG_ID']==0), 'IS_OUG'] = '0'\n",
    "mag_parcels_sdf = mag_parcels_sdf.rename(columns={\"LAND_VAL\": \"LAND_MKT_VALUE\"})\n",
    "mag_parcels_sdf = mag_parcels_sdf.rename(columns={\"TOT_VAL\": \"TOTAL_MKT_VALUE\"})\n",
    "mag_parcels_sdf = mag_parcels_sdf.rename(columns={\"residential_units\": \"UNIT_COUNT\"})\n",
    "mag_parcels_sdf = mag_parcels_sdf.rename(columns={\"building_sqft\": \"BLDG_SQFT\"})\n",
    "mag_parcels_sdf = mag_parcels_sdf.rename(columns={\"year_built\": \"BUILT_YR\"})\n",
    "mag_parcels_sdf = mag_parcels_sdf.rename(columns={\"ACREAGE\": \"PARCEL_ACRES\"})\n",
    "mag_parcels_sdf = mag_parcels_sdf.rename(columns={\"Parent_Parcel\": \"PARCEL_ID\"})\n",
    "mag_parcels_sdf['PARCEL_ID'] = mag_parcels_sdf['PARCEL_ID'].astype(str)\n",
    "\n",
    "mag_parcels_sdf['COUNTY_NAME'] = 'Utah'\n",
    "mag_parcels_sdf['COUNTY_ID'] = 49\n",
    "\n",
    "# set parcels built after 2019 to empty\n",
    "mag_parcels_sdf.loc[(mag_parcels_sdf['BUILT_YR']>2019), 'TOTAL_MKT_VALUE'] = mag_parcels_sdf['LAND_MKT_VALUE']\n",
    "mag_parcels_sdf.loc[(mag_parcels_sdf['BUILT_YR']>2019), 'building_type_id'] = 0\n",
    "mag_parcels_sdf.loc[(mag_parcels_sdf['BUILT_YR']>2019), 'UNIT_COUNT'] = 0\n",
    "mag_parcels_sdf.loc[(mag_parcels_sdf['BUILT_YR']>2019), 'BLDG_SQFT'] = 0\n",
    "\n",
    "mag_parcels_sdf = mag_parcels_sdf[['COUNTY_NAME','COUNTY_ID',\"TOTAL_MKT_VALUE\",'IS_OUG','building_type_id',\"LAND_MKT_VALUE\", \n",
    "                                    \"UNIT_COUNT\",\"BLDG_SQFT\",\"BUILT_YR\",\"PARCEL_ACRES\",\"PARCEL_ID\", 'parcel_id_REMM', \"SHAPE\"]].copy()\n",
    "\n",
    "mag_parcels_sdf.spatial.to_featureclass(location=os.path.join(gdb, \"_04_mag_parcels_processed\"),sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 28, 2022 10:55:14 AM\",\"Succeeded at Thursday, April 28, 2022 10:55:51 AM (Elapsed Time: 37.25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\temp_file.gdb\\\\_05_wfrc_mag_parcels'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge wfrc and mag parcels\n",
    "wfrc_mag_parcels = arcpy.Merge_management([parcels_reunited_lyr, os.path.join(gdb, \"_04_mag_parcels_processed\")], os.path.join(gdb, '_05_wfrc_mag_parcels'))\n",
    "arcpy.CalculateField_management(wfrc_mag_parcels, 'parcel_id_REMM', \"\"\"!OBJECTID!\"\"\", \"PYTHON3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Agriculture attribute (check this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 28, 2022 10:56:43 AM\",\"Succeeded at Thursday, April 28, 2022 10:56:58 AM (Elapsed Time: 14.86 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'wfrc_mag_parcels_lyr'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set land use type on parcels using glfu\n",
    "ag = r'.\\Inputs\\agriculture_2020.shp'\n",
    "\n",
    "wfrc_mag_parcels_lyr = arcpy.MakeFeatureLayer_management(wfrc_mag_parcels, 'wfrc_mag_parcels_lyr') \n",
    "arcpy.management.SelectLayerByLocation(wfrc_mag_parcels_lyr, \"HAVE_THEIR_CENTER_IN\", select_features=ag, selection_type=\"NEW_SELECTION\")\n",
    "\n",
    "arcpy.CalculateField_management(wfrc_mag_parcels_lyr, field='agriculture', expression=\"1\", expression_type=\"PYTHON3\")\n",
    "\n",
    "arcpy.SelectLayerByAttribute_management(wfrc_mag_parcels_lyr, 'SWITCH_SELECTION')\n",
    "\n",
    "arcpy.CalculateField_management(wfrc_mag_parcels_lyr, field='agriculture', expression=\"0\", expression_type=\"PYTHON3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear some memory\n",
    "del hui_sdf\n",
    "del merged\n",
    "# del wfrc_parcels_sdf\n",
    "del mag_parcels_sdf\n",
    "# del wfrc_mag_parcels_sdf\n",
    "del parcels_reunited_lyr\n",
    "del parcels_reunited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 28, 2022 10:57:41 AM\",\"Adding RealBldg to _05a_acre_mesh...\",\"Succeeded at Thursday, April 28, 2022 10:57:41 AM (Elapsed Time: 0.13 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\temp_file.gdb\\\\_05a_acre_mesh'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.outputCoordinateSystem = arcpy.SpatialReference('NAD 1983 UTM Zone 12N')\n",
    "desc = arcpy.Describe(wfrc_mag_parcels)\n",
    "\n",
    "#create the acre mesh- in this case, the cell_width and height calculate to 1 acre.\n",
    "acre_mesh = arcpy.management.CreateFishnet(out_feature_class = os.path.join(gdb,'_05a_acre_mesh'),\n",
    "    origin_coord = str(desc.extent.lowerLeft),\n",
    "    y_axis_coord = str(desc.extent.XMin) + \" \" + str(desc.extent.YMax + 10),\n",
    "    cell_width = 63.6, # meters\n",
    "    cell_height = 63.6, # meters\n",
    "    number_rows = '#',\n",
    "    number_columns = '#',\n",
    "    labels = 'NO_LABELS', \n",
    "    template = wfrc_mag_parcels, \n",
    "    geometry_type = 'POLYGON'\n",
    ")\n",
    "\n",
    "#Add Required Fields: RealBuildingID\n",
    "arcpy.management.AddFields(in_table=acre_mesh, field_description=[[\"RealBldg\", \"DOUBLE\", \"RealBldg\", \"\", \"\", \"\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying which parcels meet the qualifications\n",
    "Parcels_7Acre_wBuildings = arcpy.conversion.FeatureClassToFeatureClass(in_features=wfrc_mag_parcels, \n",
    "                                                                       out_path=gdb, out_name=\"_06_Parcels_7Acre_wBuildings\", \n",
    "                                                                       where_clause=\"(building_type_id IN (0, 1, 15)) And (PARCEL_ACRES >= 7) AND (IS_OUG <>  '1')\")\n",
    "\n",
    "#Identifying which buildings reside on those parcels that meet qualifications\n",
    "Buildings_7Acre_wBuildings = arcpy.analysis.SpatialJoin(target_features=addr_pts, \n",
    "                                                        join_features=Parcels_7Acre_wBuildings, \n",
    "                                                        out_feature_class=os.path.join(gdb,'_07_Buildings_7Acre_wBuildings'), \n",
    "                                                        join_operation=\"JOIN_ONE_TO_ONE\", \n",
    "                                                        join_type=\"KEEP_COMMON\",\n",
    "                                                        match_option=\"INTERSECT\", \n",
    "                                                        search_radius=\"\", \n",
    "                                                        distance_field_name=\"\")\n",
    "\n",
    "#Adding the Preserve Bldg field- used to identify which building areas to preserve\n",
    "arcpy.management.AddField(in_table=Buildings_7Acre_wBuildings, \n",
    "                                                       field_name=\"PreserveBldg\", \n",
    "                                                       field_type=\"SHORT\", \n",
    "                                                       field_precision=None, \n",
    "                                                       field_scale=None, \n",
    "                                                       field_length=None, \n",
    "                                                       field_alias=\"RealBldg\", \n",
    "                                                       field_is_nullable=\"NULLABLE\", \n",
    "                                                       field_is_required=\"NON_REQUIRED\", \n",
    "                                                       field_domain=\"\")\n",
    "\n",
    "arcpy.management.CalculateField(in_table=Buildings_7Acre_wBuildings, \n",
    "                                                    field=\"PreserveBldg\", \n",
    "                                                    expression=\"1\", \n",
    "                                                    expression_type=\"ARCADE\", \n",
    "                                                    code_block=\"\", \n",
    "                                                    field_type=\"TEXT\")\n",
    "\n",
    "Preserve_Buildings = arcpy.conversion.FeatureClassToFeatureClass(in_features=Buildings_7Acre_wBuildings, \n",
    "                                                                       out_path=gdb, out_name=\"_08_Preserve_Buildings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split mesh grids by parcel geometry to prevent overlap into neighboring parcels\n",
    "Mesh_Selected_Parcels_Identity = arcpy.Identity_analysis (acre_mesh, Parcels_7Acre_wBuildings, os.path.join(gdb,'_09_Mesh_Selected_Parcels_Identity'))\n",
    "\n",
    "#Use Spatial Join to identify which acre_mesh pieces contain those preserve_buildings\n",
    "Mesh_w_Buildings = arcpy.analysis.SpatialJoin(target_features=Mesh_Selected_Parcels_Identity, \n",
    "                           join_features=Preserve_Buildings, \n",
    "                           out_feature_class=os.path.join(gdb,'_09_Mesh_w_Buildings'), \n",
    "                           join_operation=\"JOIN_ONE_TO_ONE\", \n",
    "                           join_type=\"KEEP_ALL\",\n",
    "                           match_option=\"INTERSECT\", \n",
    "                           search_radius=\"\", \n",
    "                           distance_field_name=\"\")\n",
    "\n",
    "\n",
    "\n",
    "#convert to new Feature Class if Preserve_blg = 1\n",
    "Mesh_w_PreserveBldgs = arcpy.conversion.FeatureClassToFeatureClass(in_features=Mesh_w_Buildings, \n",
    "                                                                       out_path=gdb, out_name=\"_10_Mesh_w_PreserveBldgs\", \n",
    "                                                                       where_clause=\"PreserveBldg IN (1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the parcels with buildings on them and prep for mesh erasure and convert to feature class\n",
    "Parcels_for_Erase_select = arcpy.management.SelectLayerByLocation(in_layer=[wfrc_mag_parcels],\n",
    "                                                                 overlap_type=\"INTERSECT\", \n",
    "                                                                 select_features=Buildings_7Acre_wBuildings, \n",
    "                                                                 search_distance=\"\", \n",
    "                                                                 selection_type=\"NEW_SELECTION\", \n",
    "                                                                 invert_spatial_relationship=\"NOT_INVERT\")\n",
    "\n",
    "# ensure undesired parcels aren't selected\n",
    "arcpy.SelectLayerByAttribute_management(Parcels_for_Erase_select, 'SUBSET_SELECTION', \"(building_type_id IN (0, 1, 15)) And (PARCEL_ACRES >= 7) AND (IS_OUG <>  '1')\")\n",
    "\n",
    "\n",
    "Parcels_for_Erase= arcpy.conversion.FeatureClassToFeatureClass(in_features=Parcels_for_Erase_select, \n",
    "                                                                       out_path=gdb, out_name=\"_11_Parcels_for_Erase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_erased = arcpy.analysis.Erase(in_features=Parcels_for_Erase,\n",
    "                                      erase_features=Mesh_w_PreserveBldgs, \n",
    "                                      out_feature_class= os.path.join(gdb,'_12_parcels_erased'),\n",
    "                                      cluster_tolerance=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all building parcel attributes to zero out for the non-building pieces\n",
    "#YEAR BUILT\n",
    "parcels_erased = arcpy.management.CalculateField(in_table=parcels_erased, \n",
    "                                                                  field=\"BUILT_YR\", \n",
    "                                                                  expression=\"\"\"0\"\"\", \n",
    "                                                                  expression_type=\"PYTHON3\")\n",
    "\n",
    "#BUILDING SQFT\n",
    "parcels_erased = arcpy.management.CalculateField(in_table=parcels_erased, \n",
    "                                                                  field=\"BLDG_SQFT\", \n",
    "                                                                  expression=\"\"\"0\"\"\", \n",
    "                                                                  expression_type=\"PYTHON3\")\n",
    "\n",
    "#BUILDING TYPE ID\n",
    "parcels_erased = arcpy.management.CalculateField(in_table=parcels_erased, \n",
    "                                                                  field=\"building_type_id\", \n",
    "                                                                  expression=\"\"\"0\"\"\", \n",
    "                                                                  expression_type=\"PYTHON3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join erased parcels to original parcels- puzzle piece 1\n",
    "parcels_with_structures = arcpy.analysis.SymDiff(Parcels_for_Erase, parcels_erased, os.path.join(gdb,'_13_parcels_with_structures'))\n",
    "arcpy.AddField_management(parcels_with_structures, 'Split', 'LONG')\n",
    "arcpy.CalculateField_management(parcels_with_structures, field='Split', expression=2, expression_type=\"PYTHON3\") \n",
    "\n",
    "parcels_erased_union = arcpy.management.Merge(inputs=[parcels_erased, parcels_with_structures],\n",
    "                                           output=os.path.join(gdb,'_14_parcels_erased_union'),\n",
    "                                           add_source=\"NO_SOURCE_INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #All other parcels not included in the parcels_erased_union\n",
    "Other_parcels_select = arcpy.management.SelectLayerByLocation(in_layer=[wfrc_mag_parcels], \n",
    "                                                          overlap_type=\"INTERSECT\", \n",
    "                                                          select_features=Buildings_7Acre_wBuildings, \n",
    "                                                          search_distance=\"\", \n",
    "                                                          selection_type=\"NEW_SELECTION\", \n",
    "                                                          invert_spatial_relationship=\"INVERT\")\n",
    "\n",
    "# Other_parcels_select = arcpy.SelectLayerByAttribute_management(wfrc_mag_parcels_w_TAZID, 'NEW_SELECTION', \"(building_type_id IN (0, 1, 15)) And (PARCEL_ACRES >= 7) AND (IS_OUG <>  '1')\",  invert_where_clause=\"INVERT\")\n",
    "\n",
    "#convert selection to new feature class\n",
    "All_other_parcels= arcpy.conversion.FeatureClassToFeatureClass(in_features=Other_parcels_select, \n",
    "                                                                       out_path=gdb, \n",
    "                                                               out_name=\"_15_All_other_parcels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the non-erased, and the erased parcels back together\n",
    "prepared_parcels = arcpy.management.Merge(inputs=[All_other_parcels, parcels_erased_union],\n",
    "                                           output=os.path.join(gdb,'_16_prepared_parcels'),\n",
    "                                           add_source=\"NO_SOURCE_INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select parcels with acreage larger than 7 or haven't been erased\n",
    "parcels_YES_split_select = arcpy.management.SelectLayerByAttribute(in_layer_or_view=prepared_parcels,\n",
    "                                                                               selection_type=\"NEW_SELECTION\", \n",
    "                                                                               where_clause=\"\"\" building_type_id IN (0, 1, 15) And (PARCEL_ACRES >= 7) AND (IS_OUG <>  '1') And \n",
    "                                                                                               (FID__12_parcels_erased > -1 Or FID__12_parcels_erased IS NULL)\"\"\", \n",
    "                                                                               invert_where_clause=\"\")\n",
    "\n",
    "parcels_YES_split = arcpy.conversion.FeatureClassToFeatureClass(in_features=parcels_YES_split_select, \n",
    "                                                                       out_path=gdb, \n",
    "                                                               out_name=\"_17_parcels_YES_split\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_YES_split, field='Split', expression=1, expression_type=\"PYTHON3\") \n",
    "\n",
    "# WRONG PLACE apply taz to splitting process\n",
    "# taz_layer = arcpy.MakeFeatureLayer_management(new_taz, 'new_taz') \n",
    "# query = '''REMM IN (1)'''\n",
    "# arcpy.management.SelectLayerByAttribute(taz_layer, \"NEW_SELECTION\", query)\n",
    "parcels_YES_split_taz = arcpy.Identity_analysis(parcels_YES_split, new_taz, os.path.join(gdb,'_18_parcels_YES_split_taz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_split = arcpy.management.SubdividePolygon(in_polygons=parcels_YES_split_taz, \n",
    "                                  out_feature_class= os.path.join(gdb,'_19_parcels_split'), \n",
    "                                  method=\"EQUAL_AREAS\", \n",
    "                                  num_areas=None, \n",
    "                                  target_area=\"5 Acres\", \n",
    "                                  target_width=\"\", \n",
    "                                  split_angle=0, \n",
    "                                  subdivision_type=\"STACKED_BLOCKS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all other parcels that arent ready for splitting\n",
    "parcels_NO_split_select = arcpy.management.SelectLayerByAttribute(in_layer_or_view=prepared_parcels,\n",
    "                                                                               selection_type=\"NEW_SELECTION\", \n",
    "                                                                               where_clause=\"\"\"building_type_id IN (0, 1, 15) And (PARCEL_ACRES >= 7) AND (IS_OUG <>  '1')\n",
    "                                                                                              And (FID__12_parcels_erased > -1 Or FID__12_parcels_erased IS NULL)\"\"\", \n",
    "                                                                               invert_where_clause=\"INVERT\")\n",
    "\n",
    "\n",
    "parcels_NO_split = arcpy.conversion.FeatureClassToFeatureClass(in_features=parcels_NO_split_select, \n",
    "                                                                       out_path=gdb, \n",
    "                                                               out_name=\"_20_parcels_NO_split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging all parcels back together again\n",
    "parcels_split_merge = arcpy.management.Merge(inputs=[parcels_split, parcels_NO_split],\n",
    "                                           output=os.path.join(gdb,'_21_parcels_split_merge'),\n",
    "                                           add_source=\"NO_SOURCE_INFO\")\n",
    "\n",
    "# recalc acreage\n",
    "arcpy.AddField_management(parcels_split_merge, 'PARCEL_ACRES_NEW', 'FLOAT')\n",
    "arcpy.CalculateField_management(parcels_split_merge, \"PARCEL_ACRES_NEW\", \"\"\"!SHAPE.area@ACRES!\"\"\", \"PYTHON3\")\n",
    "# arcpy.CalculateGeometryAttributes_management(parcels_split_merge, [\"PARCEL_ACRES_NEW\", \"AREA\"], area_unit=\"ACRES\") # bugged\n",
    "\n",
    "# create layer\n",
    "parcels_split_merge_lyr = arcpy.MakeFeatureLayer_management(parcels_split_merge, 'parcels_split_merge_lyr') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 28, 2022 11:08:21 AM\",\"Succeeded at Thursday, April 28, 2022 11:08:21 AM (Elapsed Time: 0.02 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'parcels_split_merge_lyr'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete tiny parcels\n",
    "query = \"\"\" Shape_Area < 15 \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(parcels_split_merge_lyr, 'NEW_SELECTION', query)\n",
    "parcels_split_merge_lyr = arcpy.DeleteFeatures_management(parcels_split_merge_lyr)\n",
    "arcpy.SelectLayerByAttribute_management(parcels_split_merge_lyr, 'CLEAR_SELECTION', query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 28, 2022 11:11:29 AM\",\"Succeeded at Thursday, April 28, 2022 11:11:29 AM (Elapsed Time: 0.01 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'gflu_lyr'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set land use type on parcels using glfu\n",
    "gflu = '.\\Inputs\\WFRC_MAG_Base_Policy.shp'\n",
    "gflu_lyr = arcpy.MakeFeatureLayer_management(gflu, 'gflu_lyr') \n",
    "\n",
    "\n",
    "##################\n",
    "# Type 1 (SF)\n",
    "##################\n",
    "\n",
    "# query for land use type\n",
    "query = (\"\"\" GenLUType IN ('Any Development','Any Residential', 'Mixed Use SF', 'Residential SF', 'Residential SF/Retail') \n",
    "                Or (GenLUType = 'Residential' And MaxDUA <= 12)\n",
    "                Or (GenLUType = 'Agricultural' And MaxDUA < .2)\n",
    "                Or (GenLUType = 'Mixed Use' And MaxDUA <= 18)  \"\"\")\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='type1', expression=\"'t'\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "\n",
    "##################\n",
    "# Type 2 (MF)\n",
    "##################\n",
    "\n",
    "# query for land use type\n",
    "query = (\"\"\" (GenLUType IN ('Any Residential', 'Any Development', 'Industrial/Mixed Use MF', 'Mixed Use', \n",
    "                          'Residential MF/Office', 'Residential MF', 'Mixed Use MF', 'Mixed Use SF', 'Residential/Office', \n",
    "                          'Residential/Retail')) \n",
    "                          Or (GenLUType = 'Residential' And MaxDUA >= 8)\n",
    "                           \"\"\")\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# select the parcels\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='type2', expression=\"'t'\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "#######################\n",
    "# Type 3 (Industrial)\n",
    "#######################\n",
    "\n",
    "# query for land use type\n",
    "query = \"\"\" GenLUType IN ('Industrial', 'Industrial/Office', 'Any Development', 'Industrial/Mixed Use MF','Business Park') \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# select the parcels\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='type3', expression=\"'t'\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "#######################\n",
    "# Type 4 (Retail)\n",
    "#######################\n",
    "\n",
    "# query for land use type\n",
    "query = \"\"\" GenLUType IN ('Any Development', 'Industrial/Retail', 'Retail', 'Retail/Office', 'Residential/Retail', \n",
    "                          'Residential SF/Retail', 'Mixed Use', 'Commercial') \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# select the parcels\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='type4', expression=\"'t'\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "\n",
    "#######################\n",
    "# Type 5 (Office)\n",
    "#######################\n",
    "\n",
    "# query for land use type\n",
    "query = \"\"\" GenLUType IN ('Retail/Office', 'Office', 'Any Commercial', 'Residential/Office', 'Residential MF/Office','Commercial','Business Park', 'Mixed Use') \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# select the parcels\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='type5', expression=\"'t'\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "####################################\n",
    "# Type 6 (Government and Education)\n",
    "###################################\n",
    "\n",
    "# query for land use type\n",
    "query = \"\"\" GenLUType IN ('Any Development', 'Government/Education', 'Business Park') \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# select the parcels\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='type6', expression=\"'t'\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "\n",
    "####################################\n",
    "# Type 7 (Mixed Use)\n",
    "###################################\n",
    "\n",
    "# query for land use type\n",
    "query = \"\"\" GenLUType IN ('Any Development', 'Industrial/Mixed Use MF', 'Mixed Use', 'Mixed Use MF', 'Mixed Use SF', \n",
    "                          'Residential MF/Office', 'Residential SF/Retail', 'Residential/Office', 'Residential/Retail', \n",
    "                          'Retail/Office') \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# select the parcels\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='type7', expression=\"'t'\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "####################################\n",
    "# Type 8 (Other)\n",
    "###################################\n",
    "\n",
    "# # query for land use type\n",
    "# query = \"\"\" GenLUType IN ('Any Development', 'Industrial/Retail', 'Retail', 'Retail/Office', 'Residential/Retail', \n",
    "#                           'Residential SF/Retail') \"\"\"\n",
    "# arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# # select the parcels\n",
    "# arcpy.SelectLayerByLocation_management(in_layer=merged_parcels_lyr,overlap_type=\"INTERSECT\",\n",
    "#                                        select_features=gflu_lyr,\n",
    "#                                        selection_type='NEW_SELECTION')\n",
    "\n",
    "# arcpy.CalculateField_management(merged_parcels_lyr, field='type8', expression=\"'t'\".format(tag),\n",
    "#                                 expression_type=\"PYTHON3\")\n",
    "\n",
    "#################################\n",
    "# Undevelopable\n",
    "#################################\n",
    "\n",
    "# query for land use type\n",
    "query = \"\"\" GenLUType IN ('NoBuild', 'Open Space', 'Sensitive Areas','Transportation') \"\"\"\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# select the parcels\n",
    "arcpy.management.SelectLayerByLocation(parcels_split_merge_lyr, \"HAVE_THEIR_CENTER_IN\", gflu_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "arcpy.CalculateField_management(parcels_split_merge_lyr, field='NoBuild', expression=\"1\",\n",
    "                                expression_type=\"PYTHON3\")\n",
    "\n",
    "\n",
    "# clear selected parcels\n",
    "arcpy.SelectLayerByAttribute_management(parcels_split_merge_lyr, 'CLEAR_SELECTION', query)\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'CLEAR_SELECTION', query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute cleanup\n",
    "final_parcel_df = pd.DataFrame.spatial.from_featureclass(parcels_split_merge[0])\n",
    "\n",
    "# Adjust non-true zoning to false\n",
    "final_parcel_df.loc[(final_parcel_df['type1'] != 't'), 'type1'] = 'f'\n",
    "final_parcel_df.loc[(final_parcel_df['type2'] != 't'), 'type2'] = 'f'\n",
    "final_parcel_df.loc[(final_parcel_df['type3'] != 't'), 'type3'] = 'f'\n",
    "final_parcel_df.loc[(final_parcel_df['type4'] != 't'), 'type4'] = 'f'\n",
    "final_parcel_df.loc[(final_parcel_df['type5'] != 't'), 'type5'] = 'f'\n",
    "final_parcel_df.loc[(final_parcel_df['type6'] != 't'), 'type6'] = 'f'\n",
    "final_parcel_df.loc[(final_parcel_df['type7'] != 't'), 'type7'] = 'f'\n",
    "final_parcel_df.loc[(final_parcel_df['type8'] != 't'), 'type8'] = 'f'\n",
    "\n",
    "# divide land value by this number for new approximate value\n",
    "final_parcel_df['Split_Factor'] = final_parcel_df['PARCEL_ACRES']/final_parcel_df['PARCEL_ACRES_NEW']\n",
    "final_parcel_df['PARCEL_ACRES'] = final_parcel_df['PARCEL_ACRES_NEW']\n",
    "\n",
    "fields = ['parcel_id_REMM','COUNTY_NAME','TAZID', 'COUNTY_ID', 'PARCEL_ID', 'TOTAL_MKT_VALUE', 'LAND_MKT_VALUE', 'UNIT_COUNT', 'BLDG_SQFT', 'FLOORS_CNT',\n",
    "         'BUILT_YR', 'EFFBUILT_YR', 'IS_OUG','max_dua', 'max_far', 'max_height', 'type1', 'type2', 'type3', 'type4', 'type5', 'type6', \n",
    "         'type7','type8', 'agriculture', 'basebldg', 'NoBuild', 'redev_friction', 'building_type_id', 'x', 'y', \n",
    "        'PARCEL_ACRES', 'Split','Split_Factor', 'SHAPE']\n",
    "\n",
    "# save old parcel id\n",
    "final_parcel_df = final_parcel_df[fields].copy()\n",
    "final_parcel_df['parcel_id_REMM_old'] = final_parcel_df['parcel_id_REMM']\n",
    "\n",
    "# generate unique building id for split parcels\n",
    "final_parcel_df.loc[(final_parcel_df['Split'].isna() == True), 'Split'] = 0\n",
    "split_parcels = final_parcel_df[final_parcel_df['Split'] == 1].copy()\n",
    "nonsplit_parcels = final_parcel_df[(final_parcel_df['Split']==0) | (final_parcel_df['Split']==2)].copy()\n",
    "count = final_parcel_df.shape[0]\n",
    "split_parcels['parcel_id_REMM'] = count + split_parcels.index + 1\n",
    "\n",
    "# merge parcels back together once id has been figured out\n",
    "final_parcel_df = pd.concat([nonsplit_parcels, split_parcels])\n",
    "del nonsplit_parcels\n",
    "del split_parcels\n",
    "\n",
    "# set residential unit count of new parcels resulting from split to 0\n",
    "final_parcel_df.loc[(final_parcel_df['Split']==1), 'UNIT_COUNT'] = 0\n",
    "\n",
    "# set parcels with null unit counts to 0\n",
    "final_parcel_df.loc[(final_parcel_df['UNIT_COUNT'].isna()), 'UNIT_COUNT'] = 0\n",
    "\n",
    "# recalc land value and total market value using split factor\n",
    "final_parcel_df.loc[(final_parcel_df['Split']==1), 'LAND_MKT_VALUE'] = final_parcel_df['LAND_MKT_VALUE'] / final_parcel_df['Split_Factor']\n",
    "final_parcel_df.loc[(final_parcel_df['Split']==1), 'TOTAL_MKT_VALUE'] = final_parcel_df['LAND_MKT_VALUE']\n",
    "final_parcel_df.loc[(final_parcel_df['Split']==2), 'TOTAL_MKT_VALUE'] = (final_parcel_df['TOTAL_MKT_VALUE'] - final_parcel_df['LAND_MKT_VALUE']) + (final_parcel_df['LAND_MKT_VALUE'] / final_parcel_df['Split_Factor'])\n",
    "final_parcel_df.loc[(final_parcel_df['Split']==2), 'LAND_MKT_VALUE'] = final_parcel_df['LAND_MKT_VALUE'] / final_parcel_df['Split_Factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix county ids\n",
    "final_parcel_df.loc[final_parcel_df['COUNTY_NAME'] == 'Davis', 'COUNTY_ID'] = '11'\n",
    "final_parcel_df.loc[final_parcel_df['COUNTY_NAME'] == 'Salt Lake', 'COUNTY_ID'] = '35'\n",
    "final_parcel_df.loc[final_parcel_df['COUNTY_NAME'] == 'Weber', 'COUNTY_ID'] = '57'\n",
    "\n",
    "# add type column\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==0), 'TYPE'] = 'Empty Buildable'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==1), 'TYPE'] = 'Single Family Res'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==2), 'TYPE'] = 'Multi Family Res'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==3), 'TYPE'] = 'Industrial'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==4), 'TYPE'] = 'Retail'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==5), 'TYPE'] = 'Office'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==6), 'TYPE'] = 'Governmental'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==7), 'TYPE'] = 'Mixed Use'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==8), 'TYPE'] = 'Other'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==9), 'TYPE'] = 'Educational'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==10), 'TYPE'] = 'Church'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==11), 'TYPE'] = 'Group Quarters'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==12), 'TYPE'] = 'Commons'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==13), 'TYPE'] = 'Healthcare'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==14), 'TYPE'] = 'Open Space Non-Buildable'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==15), 'TYPE'] = 'Agriculture'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==16), 'TYPE'] = 'Utilities'\n",
    "final_parcel_df.loc[(final_parcel_df['building_type_id']==99), 'TYPE'] = 'No Build'\n",
    "\n",
    "# make fields REMM compatible\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"LAND_MKT_VALUE\": \"land_value\"})\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"COUNTY_NAME\": \"CO_NAME\"})\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"COUNTY_ID\": \"county_id\"})\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"BLDG_SQFT\": \"building_sqft\"})\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"UNIT_COUNT\": \"residential_units\"})\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"BUILT_YR\": \"year_built\"})\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"PARCEL_ACRES\": \"parcel_acres\"})\n",
    "final_parcel_df = final_parcel_df.rename(columns={\"TYPE\": \"building_type\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use spatial joins to get missing attribute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export only the shape and ids for spatial joining (~13 min)\n",
    "parcels_for_sj_df= final_parcel_df[['parcel_id_REMM','max_dua', 'SHAPE']].copy()\n",
    "parcels_for_sj = os.path.join(gdb,'_022_parcels_id_only')\n",
    "parcels_for_sj_df.spatial.to_featureclass(location=parcels_for_sj, sanitize_columns=False)\n",
    "del parcels_for_sj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to retrieve max dua\n",
    "target_features = parcels_for_sj\n",
    "join_features = gflu\n",
    "output_features = os.path.join(gdb, \"_023_parcels_gflu_2019_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('MaxDUA')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflu_old = r'E:\\Projects\\REMM-Input-Data-Prep-2019\\Parcels\\2020-WFRC\\Inputs\\Old_Policy.gdb\\max_dua_rtp2015'\n",
    "\n",
    "# use spatial join to retrieve old max dua\n",
    "target_features = parcels_for_sj\n",
    "join_features = gflu_old\n",
    "output_features = os.path.join(gdb, \"_023_parcels_gflu_2015_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('MaxDUA')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj4 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join  to get tazid from 8.3.2 traffic analysis zones\n",
    "target_features = parcels_for_sj\n",
    "join_features = old_taz\n",
    "output_features = os.path.join(gdb, \"_023_parcels_taz832_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('TAZID')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'First'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj2 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to get tazid from 9.0.0 traffic analysis zones\n",
    "target_features = parcels_for_sj\n",
    "join_features = new_taz\n",
    "output_features = os.path.join(gdb, \"_023_parcels_taz900_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('TAZID')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'First'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj3 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to get census tract id\n",
    "target_features = parcels_for_sj\n",
    "join_features = census_tracts\n",
    "output_features = os.path.join(gdb, \"_023_parcels_tract_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('GEOID')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'First'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj6 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to get missing square footage from old data\n",
    "target_features = parcels_for_sj\n",
    "join_features = nonres_pts\n",
    "output_features = os.path.join(gdb, \"_023_parcels_sqft_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('old_nonres_sqft')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Sum'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj5 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"INTERSECT\")\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max far\n",
    "target_features = parcels_for_sj\n",
    "join_features = centers\n",
    "output_features = os.path.join(gdb, \"_023_parcels_centers_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('MaxFAR')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj7 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to get local FAR for calcuating missing square footage\n",
    "target_features = parcels_for_sj\n",
    "join_features = base_year_surface1\n",
    "output_features = os.path.join(gdb, \"_023_parcels_bys1_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('FAR_SF')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('FAR_MF')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('FAR_IND')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('FAR_NONIND')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj9 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to get local FAR for calcuating missing square footage\n",
    "target_features = parcels_for_sj\n",
    "join_features = base_year_surface2\n",
    "output_features = os.path.join(gdb, \"_023_parcels_bys2_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# attribute to summarize\n",
    "fieldindex = fieldmappings.findFieldMapIndex('MAXDUA_MED')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Max'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('YB_SF')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'First'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('YB_MF')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'First'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('YB_IND')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'First'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "fieldindex = fieldmappings.findFieldMapIndex('YB_NONIND')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'First'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj10 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and merge spatial join tables together (~8 min)\n",
    "sj_df = pd.DataFrame.spatial.from_featureclass(sj[0])[['parcel_id_REMM', 'MaxDUA']].copy()\n",
    "sj_df.columns = ['parcel_id_REMM', 'MaxDUA_New']\n",
    "\n",
    "sj4_df = pd.DataFrame.spatial.from_featureclass(sj4[0])[['parcel_id_REMM', 'MaxDua']].copy()\n",
    "sj4_df.columns = ['parcel_id_REMM', 'MaxDUA_Old']\n",
    "\n",
    "sj2_df = pd.DataFrame.spatial.from_featureclass(sj2[0])[['parcel_id_REMM', 'TAZID']].copy()\n",
    "sj2_df.columns = ['parcel_id_REMM', 'TAZID_832']\n",
    "\n",
    "sj3_df = pd.DataFrame.spatial.from_featureclass(sj3[0])[['parcel_id_REMM', 'TAZID']].copy()\n",
    "sj3_df.columns = ['parcel_id_REMM', 'TAZID_900']\n",
    "\n",
    "sj6_df = pd.DataFrame.spatial.from_featureclass(sj6[0])[['parcel_id_REMM', 'GEOID']].copy()\n",
    "sj6_df.columns = ['parcel_id_REMM', 'Tract_GEOID']\n",
    "\n",
    "sj5_df = pd.DataFrame.spatial.from_featureclass(sj5[0])[['parcel_id_REMM', 'old_nonres_sqft']].copy()\n",
    "sj5_df.columns = ['parcel_id_REMM', 'old_nonres_sqft']\n",
    "\n",
    "sj7_df = pd.DataFrame.spatial.from_featureclass(sj7[0])[['parcel_id_REMM', 'MaxFAR']].copy()\n",
    "sj7_df.columns = ['parcel_id_REMM', 'MaxFAR_New']\n",
    "\n",
    "sj9_df = pd.DataFrame.spatial.from_featureclass(sj9[0])[['parcel_id_REMM', 'FAR_SF','FAR_MF','FAR_IND','FAR_NONIND']].copy()\n",
    "\n",
    "sj10_df = pd.DataFrame.spatial.from_featureclass(sj10[0])[['parcel_id_REMM', 'MAXDUA_MED', 'YB_SF', 'YB_MF', 'YB_IND', 'YB_NONIND']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Max DUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671812, 37)\n",
      "(2228, 42)\n",
      "(1689, 42)\n"
     ]
    }
   ],
   "source": [
    "# track null duas\n",
    "print(final_parcel_df[final_parcel_df['max_dua'].isna()].shape)\n",
    "\n",
    "# max dua from 2019\n",
    "merged = final_parcel_df.merge(sj_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "merged = merged.merge(sj10_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "\n",
    "del final_parcel_df\n",
    "del sj10_df\n",
    "del sj_df\n",
    "\n",
    "merged['max_dua'] = merged['MaxDUA_New']\n",
    "del merged['MaxDUA_New']\n",
    "print(merged[merged['max_dua'].isna()].shape)\n",
    "\n",
    "# max dua from 2015\n",
    "merged = merged.merge(sj4_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "del sj4_df\n",
    "merged.loc[(merged['max_dua'].isna()==True) & (merged['MaxDUA_Old'] >= 0), 'max_dua'] = merged['MaxDUA_Old']\n",
    "del merged['MaxDUA_Old']\n",
    "print(merged[merged['max_dua'].isna()].shape)\n",
    "\n",
    "# set max dua of open space parcels to 0\n",
    "merged.loc[(merged['building_type_id']==14), 'max_dua'] = 0\n",
    "\n",
    "# set max dua using zoning surface\n",
    "merged.loc[(merged['max_dua'].isna()==True) & (merged['MAXDUA_MED'] >= 0), 'max_dua'] = merged['MAXDUA_MED']\n",
    "del merged['MAXDUA_MED']\n",
    "\n",
    "# set zeros to null\n",
    "merged.loc[(merged['max_dua'] == 0), 'max_dua'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing \"year_built\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.loc[(((merged['year_built'].isna()==True) | (merged['year_built'] <= 0)) & (merged['building_type_id'].isin([1]))), 'year_built'] = merged['YB_SF']\n",
    "merged.loc[(((merged['year_built'].isna()==True) | (merged['year_built'] <= 0)) & (merged['building_type_id'].isin([2]))), 'year_built'] = merged['YB_MF']\n",
    "merged.loc[(((merged['year_built'].isna()==True) | (merged['year_built'] <= 0)) & (merged['building_type_id'].isin([3]))), 'year_built'] = merged['YB_IND']\n",
    "merged.loc[(((merged['year_built'].isna()==True) | (merged['year_built'] <= 0)) & (merged['building_type_id'].isin([4,5,6,7,8,9,10,11,13]))), 'year_built'] = merged['YB_NONIND']\n",
    "\n",
    "\n",
    "del merged['YB_SF']\n",
    "del merged['YB_MF']\n",
    "del merged['YB_IND']\n",
    "del merged['YB_NONIND']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Max FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(sj7_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "del sj7_df\n",
    "merged.loc[(merged['MaxFAR_New'] > 0), 'max_far'] = merged['MaxFAR_New']\n",
    "del merged['MaxFAR_New']\n",
    "\n",
    "# set non residential parcels\n",
    "merged.loc[((merged['max_far'].isna()==True) & (merged['type1'] != 1) & (merged['type2'] != 1)), 'max_far'] = .5\n",
    "        \n",
    "# set industrial only parcels\n",
    "merged.loc[((merged['type3'] == 1) & (merged['type1'] == 1) & (merged['type2'] == 1) & (merged['type4'] == 1) &\n",
    "            (merged['type5'] == 1) & (merged['type6'] == 1) & (merged['type7'] == 1) & (merged['type8'] == 1) & (merged['max_far'].isna()==True)), 'max_far'] = .41\n",
    "\n",
    "# set max far of open space parcels to 0\n",
    "merged.loc[(merged['building_type_id']==14), 'max_far'] = 0\n",
    "\n",
    "# set zeros to null\n",
    "merged.loc[(merged['max_far'] == 0), 'max_far'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing \"building_sqft\" from 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150781, 38)\n",
      "(148158, 38)\n"
     ]
    }
   ],
   "source": [
    "merged = merged.merge(sj5_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "del sj5_df\n",
    "\n",
    "print(merged[(merged['building_sqft'].isna()) |  (merged['building_sqft'] <= 0)].shape)\n",
    "merged.loc[(((merged['building_sqft'].isna()==True) | (merged['building_sqft'] <= 0)) & ~(merged['building_type_id'].isin([1,2]))), 'building_sqft'] = merged['old_nonres_sqft']\n",
    "print(merged[(merged['building_sqft'].isna()) |  (merged['building_sqft'] <= 0)].shape)\n",
    "del merged['old_nonres_sqft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(sj9_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "del sj9_df\n",
    "\n",
    "merged.loc[(((merged['building_sqft'].isna()==True) | (merged['building_sqft'] <= 0)) & (merged['building_type_id'].isin([1]))), 'building_sqft'] = merged['FAR_SF'] * merged['parcel_acres']\n",
    "merged.loc[(((merged['building_sqft'].isna()==True) | (merged['building_sqft'] <= 0)) & (merged['building_type_id'].isin([2]))), 'building_sqft'] = merged['FAR_MF'] * merged['parcel_acres']\n",
    "merged.loc[(((merged['building_sqft'].isna()==True) | (merged['building_sqft'] <= 0)) & (merged['building_type_id'].isin([3]))), 'building_sqft'] = merged['FAR_IND'] * merged['parcel_acres']\n",
    "merged.loc[(((merged['building_sqft'].isna()==True) | (merged['building_sqft'] <= 0)) & (merged['building_type_id'].isin([4,5,6,7,8,9,10,11,13]))), 'building_sqft'] = merged['FAR_NONIND'] * merged['parcel_acres']\n",
    "\n",
    "merged['building_sqft'] = merged['building_sqft'].fillna(0)\n",
    "merged['building_sqft'] = merged['building_sqft'].astype(int)\n",
    "\n",
    "\n",
    "del merged['FAR_SF']\n",
    "del merged['FAR_MF']\n",
    "del merged['FAR_IND']\n",
    "del merged['FAR_NONIND']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add zone ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taz832\n",
    "merged = merged.merge(sj2_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "del sj2_df\n",
    "\n",
    "# taz 900\n",
    "merged = merged.merge(sj3_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "del sj3_df\n",
    "\n",
    "# Census Tract GEOID\n",
    "merged = merged.merge(sj6_df, left_on='parcel_id_REMM', right_on='parcel_id_REMM', how='left')\n",
    "del sj6_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parcel_id_REMM', 'CO_NAME', 'TAZID', 'county_id', 'PARCEL_ID',\n",
       "       'TOTAL_MKT_VALUE', 'land_value', 'residential_units', 'building_sqft',\n",
       "       'FLOORS_CNT', 'year_built', 'EFFBUILT_YR', 'IS_OUG', 'max_dua',\n",
       "       'max_far', 'max_height', 'type1', 'type2', 'type3', 'type4', 'type5',\n",
       "       'type6', 'type7', 'type8', 'agriculture', 'basebldg', 'NoBuild',\n",
       "       'redev_friction', 'building_type_id', 'x', 'y', 'parcel_acres', 'Split',\n",
       "       'Split_Factor', 'SHAPE', 'parcel_id_REMM_old', 'building_type',\n",
       "       'TAZID_832', 'TAZID_900', 'Tract_GEOID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Input-Data-Prep-2019\\\\Parcels\\\\2020-WFRC\\\\Outputs\\\\remm_base_year_2019.gdb\\\\parcels_2019'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.spatial.to_featureclass(location=os.path.join(gdb2,'parcels_2019'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 28, 2022 1:46:53 PM\",\"Succeeded at Thursday, April 28, 2022 1:47:19 PM (Elapsed Time: 25.73 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\remm_base_year_2019.gdb\\\\residential_centroids_2019'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert residential parcels to pts for popsim\n",
    "final_parcels_lyr = arcpy.MakeFeatureLayer_management(os.path.join(gdb2,'parcels_2019'), 'final_parcels_lyr', where_clause=\"\"\" building_type_id IN (1, 2) \"\"\") \n",
    "arcpy.FeatureToPoint_management(final_parcels_lyr, os.path.join(gdb2,'residential_centroids_2019'), \"INSIDE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate ids\n",
    "id_summary = pd.DataFrame(merged['parcel_id_REMM'].value_counts()).reset_index()\n",
    "id_summary.columns = ['id','count']\n",
    "dups = id_summary[id_summary['count']>1]\n",
    "dups_ids = dups['id'].to_list()\n",
    "pdups = merged[merged['parcel_id_REMM'].isin(dups_ids)]\n",
    "pdups = pdups[['parcel_id_REMM','Split_Factor', 'SHAPE']].copy()\n",
    "print(pdups.shape)\n",
    "pdups.spatial.to_featureclass(location=os.path.join(gdb,'_024_duplicates'))\n",
    "del id_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.startfile(r\".\\Review.aprx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d317b2672061d56524fcc1a94907fb406961cfb6f073b94c4a68211629b9774"
  },
  "kernelspec": {
   "display_name": "Clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
